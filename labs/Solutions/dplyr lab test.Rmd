---
title: 'Lab 7: Data cleaning with dplyr'
output:
  pdf_document:
    highlight: zenburn
    number_sections: yes
  html_document:
    highlight: espresso
    theme: cerulean
---

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(eval=FALSE, warning=FALSE, message=FALSE, fig.height=4, fig.width=4) 
```

# Introduction 
When working with data you must:

1. Figure out what you want to do.
2. Precisely describe what you want in the form of a computer program.
3. Execute the code.

The dplyr package makes each of these steps as fast and easy as possible by:

1. Elucidating the most common data manipulation operations, so that your options are helpfully constrained when thinking about how to tackle a problem.
2. Providing simple functions that correspond to the most common data manipulation verbs, so that you can easily translate your thoughts into code.
3. Using efficient data storage backends, so that you spend as little time waiting for the computer as possible.

The goal of this lesson is to introduce you to the basic tools that dplyr provides, and show how you to apply them to data frames.

You must have the `knitr`, `dplyr`, `nycflights13` and `hflights` packages installed before you can proceed.

# The 5 basic verbs
The `dplyr` package contains five key data manipulation functions, also called verbs:

* `select()`: Returns a subset of the columns.
* `filter()`: Returns a subset of the rows.
* `arrange()`: Reorders the rows according to single or multiple variables.
* `mutate()`: Adds columns from existing data.
* `summarise()`: Reduces each group to a single row by calculating aggregate measures.

You will learn how to use these verbs in the `dplyr` `Swirl` lesson. 


## Practice

```{r load_packages}
lapply(c("knitr", "dplyr", "nycflights13", "hflights"),require,character.only = TRUE)
```

For this exercise, at each step use the assignment operator `<-` to store the results into a new data table and use that data in the next step. You will use the `hflights` data set which is data on  flights departing from two Houston airports in 2011

1. Use `select()` to extract the following variables: `Distance`, `AirTime`, and `Speed`

```{r select}
s_flights <- select(flights, dep_time, arr_time, arr_delay, dep_delay, air_time)
```

2. Use `filter()` to select only the flights who arrived early. (_Hint: look at ?flights to find out how an early arrival is denoted_)

```{r hint_and_filter}
?flights
f_flights <- filter(s_flights, arr_delay < 0)
```

3. Use `mutate()` to create a new variable `AirTime` that calculates the total time the plane is in the air. 


```{r mutate}
head(f_flights)
m_flights <- mutate(f_flights, 
                    AirTime = (floor(arr_time/100)-floor(dep_time/100)) * 60 + (arr_time/100 - floor(arr_time/100))*100 - (dep_time/100 - floor(dep_time/100))*100);m_flights
```

4. Use `arrange()` to order the previous data frame by ascending `AirTime`.

```{r arrange_ascending}
a_flights <- arrange(m_flights, air_time)
```

5. Use `slice()` to select the flight with the shortest time in the air. (_Hint: the shorteset flight should be in row 1 after you sort by AirTime_)

```{r slice_first}
ss_flights <- slice(a_flights, 1)
ss_flights
```

<!-- What order of operations should we use to to find the average value of the ArrDelay (arrival delay) variable for all American Airline flights in the  hflights tbl? 
first select(), then summarise().
first filter(), then summarise(). **
first summarise(), then select().
first summarise(), then filter(). 


How many weekend flights flew a distance of more than 1000 miles but had a total delay time of less than 15 minutes?
247,246 flights
111,187 flights
104,954 flights
104,011 flights **


filter(flights, distance > 1000, arr_delay + dep_delay < 15)
-->

# Additional Helper functions
`dplyr` comes with 6 helper functions that can help you select variables. These functions find groups of variables to select, based on their names. They can only be used inside `select()`. Here are 3 of the most common. 


* `starts_with("X")`: every name that starts with "X".

```{r starts_with}
select(planes, starts_with("tail"))
```

*  `ends_with("X")`: every name that ends with "X".

```{r ends_with} 
select(planes, ends_with("er"))
```

*  `contains("X")`: every name that contains "X".

```{r contains}
select(planes, contains("eng"))
```

*Watch out*: Surround character strings with quotes when you pass them to a helper function, but do not surround variable names with quotes if you are not passing them to a helper function.

```{r, error=TRUE}
select(planes, contains("engine"))
select(planes, "engine")
select(planes, engine)
```

## Practice
Still using the `flights` data table, select columns with the following conditions: 

1. All variables that start with the letter d.

```{r start_d}
select(flights, starts_with("d"))
```

2. All variables that end with *time*.

```{r end_time}
select(flights, ends_with("time"))
```

3. All variables that contain an underscore. 

```{r contain__}
select(flights, contains("_"))
```

# Grouped Operations
The above verbs are useful, but they become really powerful when you combine them with the idea of "group by", repeating the operation individually on groups of observations within the dataset. In dplyr, you use the `group_by()` function to describe how to break a dataset down into groups of rows. You can then use the resulting object in exactly the same functions as above; they'll automatically work "by group" when the input is a grouped.

Let's demonstrate how some of these functions work after grouping the flights data set by month. 

```{r group_by_month}
by_month <- group_by(flights, month)
```

* Now let's `select()` the carrier variable. grouped `select()` is the same as ungrouped `select()`, excepted that retains grouping variables are always retained.

```{r select_carrier}
by_month <- group_by(flights, month)
select(by_month, carrier)
```

* If we want to sort the data, `arrange()` orders first by grouping variables, then by the sorting variable. 

```{r arrange_dist}
how_long <- arrange(by_month, distance)
how_long
```

* Now that the data is sorted by shortest to longest distance, we can use `slice()` extract the shortest flight per month. 

```{r shortest_flight}
slice(how_long, 1)
```

* The `summarise()` verb allows you to calculate summary statistics for each group. For example, the average distance flown per month. 

```{r mean_airtime}
summarise(by_month, avg_airtime = mean(distance, na.rm=TRUE))
```

Or simply the total number of flights per month. 

```{r flights_per_month}
summarise(by_month, count=n())
```

Note we can get the exact same information using a `table()`. 

```{r tabs}
table(flights$month)
```

Typically, there are multiple ways to achieve the same goal in R. 

# Chaining Operations
Consider the following group of operations that take the data set `flights`, and produce a final data set (`a4`) that contains only the flights where the daily average delay is greater than a half hour. 

```{r half_hour_delay}
a1 <- group_by(flights, year, month, day)
a2 <- select(a1, arr_delay, dep_delay)
a3 <- summarise(a2,
                arr = mean(arr_delay, na.rm = TRUE),
                dep = mean(dep_delay, na.rm = TRUE))
a4 <- filter(a3, arr > 30 | dep > 30)
head(a4)
```

It does the trick, but what if you don't want to save all the intermediate results (`a1` - `a3`)? Well these verbs are `function`, so they can be wrapped inside other functions to create a nesting type structure.  

```{r all_at_once}
filter(
  summarise(
    select(
      group_by(flights, year, month, day),
      arr_delay, dep_delay
    ),
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ),
  arr > 30 | dep > 30
)
```

Woah, that is HARD to read! This is difficult to read because the order of the operations is from inside to out, and the arguments are a long way away from the function. To get around this problem, dplyr provides the `%>%` operator. `x %>% f(y)` turns into `f(x, y)` so you can use it to rewrite multiple operations so you can read from left-to-right, top-to-bottom:

```{r pipe_operator}
flights %>%
  group_by(year, month, day) %>%
  select(arr_delay, dep_delay) %>%
  summarise(
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ) %>%
  filter(arr > 30 | dep > 30)
```

Another way you can read this is by thinking "and then" when you see the `%>%` operator. So the above code takes the data set flights
.. and then groups by day
.. and then selects the delay varibles
.. and then calculates the means
.. and then filters on a delay over half hour. 

The same 4 steps that resulted in the `a4` data set, but without all the intermediate data saved! This can be **very important** when dealing with Big Data. `R` stores all data in memory, so if your little computer only has 2G of RAM and you're working with a data set that is 500M in size, your computers memory will be used up fast. `a1` takes 500M, `a2` another 500M, by now your computer is getting slow. Make another copy at `a3` and it gets worse, `a4` now likely won't even be able to be created because you'll be out of memory. 


## Practice
Keeping with the airline theme, we are going to use the `hflights` data set. Read a little bit about this data set in `?hflights`.

Use dplyr functions and the pipe operator (` %>% `) to transform the following English sentences into R code:

1. Take the hflights data set and then ...
2. Add a variable named diff that is the result of subtracting TaxiIn from TaxiOut, and then ...
3. Pick all of the rows whose diff value does not equal NA, and then ...
4. Summarise the data set with a value named avg that is the mean diff value.  
5. Store the result in the variable p.

```{r and_then}
p <-
  hflights %>%
  mutate(diff = TaxiOut - TaxiIn) %>%
  filter(!is.na(diff)) %>%
  summarise(avg = mean(diff))
p
```

#### Challenge Question: Do you drive or fly? 
You can answer sophisticated questions by combining the verbs of dplyr. Now you will examine whether it sometimes makes sense to drive instead of fly. You will begin by making a data set that contains relevant variables. Then, you will find flights whose equivalent average velocity is lower than the velocity when traveling by car.

1. Define a data set named `d` that contains just the `Dest`, `UniqueCarrier`, `Distance`, and `ActualElapsedTime` columns of `hflights` as well as two additional variables: `RealTime` and `mph.RealTime` should be created as the actual elapsed time plus 100 minutes. This will be an estimate of how much time a person spends getting from point A to point B while flying, including getting to the airport, security checks, etc. mph will be the miles per hour that a person on the flight traveled based on the RealTime of the flight.

```{r create_d}
d <- hflights %>%
  select(Dest, UniqueCarrier, Distance, ActualElapsedTime) %>%
  mutate(RealTime = ActualElapsedTime + 100,mph.RealTime = Distance/RealTime * 60)
```

2. On many highways you can drive at 70 mph. Continue with `d` to calculate the following variables: 

* `n_less`, the number of flights whose mph value does not equal NA that traveled at less than 70 mph in real time
* `n_dest`, the number of destinations that were traveled to at less than 70 mph (Hint: `n_distinct` function)
* `min_dist`, the minimum distance of these flights
* `max_dist`, the maximum distance of these flights

```{r}
d %>%
  filter(!is.na(mph.RealTime) & mph.RealTime < 70) %>%
  summarise(n_less = n(), n_dest = n_distinct(Dest), min_dist = min(Distance), max_dist = max(Distance))
```

This suggests that some flights might be less efficient than driving in terms of speed. But is speed all that matters? Flying imposes burdens on a traveler that driving does not. For example, airplane tickets are very expensive. Air travelers also need to limit what they bring on their trip and arrange for a pick up or a drop off. Given these burdens we might demand that a flight provide a large speed advantage over driving.  

Let's define preferable flights as flights that are 150% faster than driving, i.e. that travel 105 mph *or* greater in real time. _Also, assume that cancelled or diverted flights are less preferable than driving_.

Write an adapted version of the solution to the previous exercise in an all-in-one fashion (i.e. in a single expression without 
intermediary variables, using %>%) to find:
  
* `n_non` - the number of non-preferable flights in hflights,
* `p_non` - the percentage of non-preferable flights in hflights,
* `n_dest` - the number of destinations that non-preferable flights traveled to,
* `min_dist` - the minimum distance that non-preferable flights traveled,
* `max_dist` - the maximum distance that non-preferable flights traveled.

To maintain readability in this advanced exercise, start your operations with a `select()` function to retain only the five columns that will be needed for the subsequent calculation steps.

```{r ALL_IN_ONEE}
hflights %>% 
  select(Dest, UniqueCarrier, Distance, ActualElapsedTime, Diverted, Cancelled) %>%
  mutate(RealTime = ActualElapsedTime + 100,mph.RealTime = Distance/RealTime * 60) %>%
  filter(!is.na(mph.RealTime) & mph.RealTime >= 105 & Diverted == 0 & Cancelled == 0) %>%
  summarise(n_non = n(),asd = n_non/count(hflights), n_dest = n_distinct(Dest), min_dist = min(Distance), max_dist = max(Distance))
```  

** Whew! That was intense! Congratulations on making it this far! It takes a lot of concentration and puzzle solving to come up with a solution to get from the data you have to the data you want so that you can answer complex questions. **
    
    
# Additional Resources
The ability to manipulate, arrange and clean up data is an extremely important skill to have. It is advised that you review at least one other tutorial method for using dplyr if you are still uncomfortable with it. Remember, it is all about practice. The more you use it the easier it will become!

* Interactive [Data Camp](https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial) lesson. Data Camp is like Swirl on steriods. A very awesome learning tool. 
* [Dplyr vignette](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)
* [Hands-on dplyr tutorial for faster data manipulation in R](https://www.youtube.com/watch?v=jWjqLW-u3hc) You Tube video by Data School
* This [video recording](https://uw.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=4b82a6bf-2b3d-44d7-8467-a2e49ea59c84) given by Hadley Wickham at the Summer Institute for Statistics for Big Data, Module on Visualizing Big Data in July 2015
* These video recordings[part1](https://www.youtube.com/watch?v=8SGif63VW6E)/[part2](https://www.youtube.com/watch?v=Ue08LVuk790) from Hadley's tutorial at UseR! 2014 conference at UCLA. 
* Michael Levy's [talk](https://www.youtube.com/watch?v=KCKBmWsRQko) at the Davis R User's group, October 2014. 

